# 카프카란? 
분산 이벤트 스트리밍 플랫폼

## 카프카의 구성요소
1. 카프카 클러스터: 메시지를 저장하는 저장소. 하나의 카프카 클러스터는 여러개의 브로커로 구성됨. 
- 브로커 - 카프카 클러스터를 구성하는 서버
- 주키퍼 클러스터 - 카프카 클러스터의 메타데이터를 저장하는 서버
2. 프로듀서 - 카프카 클러스터에 메시지를 발행하는 애플리케이션
3. 컨슈머 - 카프카 클러스터에서 메시지를 읽어와서 필요한 처리를 하는 애플리케이션

## 토픽
- 토픽은 각각의 메시지를 구분하는 단위로 사용 -> 폴더나, 메일함같은 것임.
- 한개의 토픽은 한개 이상의 파티션으로 구성

## 파티션
- **파티션**은 데이터 처리를 효율적으로 하기 위한 핵심 요소다. 파티션은 큐를 나눠 병렬 처리를 가능하게 하는 기본 단위이며, 각 토픽은 하나 이상의 파티션으로 나눠져 있다. 파티션의 수를 줄이는 것은 복잡하고 위험할 수 있지만 늘리는것은 쉽다. 따라서 초기 설계단계에서 파티션 수를 신중하게 결정해야 한다.

### 파티션 특징
1. 병렬처리: 다양한 컨슈머(consumer)가 서로 다른 파티션에서 데이터를 동시에 읽을 수 있다. 이는 처리 속도를 크게 향상시킨다.
2. 순서보장: 하나의 파티션 내에서는 메시지의 순서가 보장되어, 순차적인 데이터 처리가 필요할 때 유용하다.
3. 확장성: 파티션을 여러 노드에 분산시켜 저장할 수 있어서, 시스템의 확장성을 높일 수 있다.

### 여러 파티션과 프로듀서 
- 토픽이 여러 파티션으로 구성.
> ### 프로듀서는 어떻게 어떤 파티션에 저장하는가
> #### 라운드-로빈
> 프로듀서가 메시지를 보내는 순서대로 파티션에 적재합니다. 하지만 이러한 방식은 순수 라운드로빈 방식이고 카프카는 기본적으로 sticky 라운드-로빈 방식을 사용하는데, 한 파티션에 몇건의 메시지를 배치로 보내고 파티션을 변경합니다.  
> #### 키-해시 전략
> 메시지의 순서를 보장하고 싶으면 키를 함께 메시지에 보낸다 카프카는 키값을 해싱하여 같은 해시값의 메시지는 같은 파티션에 적재한다. (ex.주문생성->주문완료->주문배송)

## 여러 파티션과 컨슈머 
- 컨슈머는 컨슈머 그룹에 속함
- 한개의 파티션은 컨슈머그룹의 한개 컨슈머만 연결 가능
  - 즉 컨슈머그룹에 속한 컨슈머들은 한 파티션을 공유할 수 없음
  - 한 컨슈머그룹 기준으로 파티션의 메시지는 순서대로 처리

## 오프셋
- 프로듀서가 넣은 메시지는 파티션의 0부터 시작하는 순차적인 오프셋 번호를 할당한다.
- 새 메시지가 파티션에 추가 될때마다 그 메시지에는 마지막 메시지의 오프셋에 1을 더한값이 할당된다. 예를들어 'MessageA'다음에 'MessageB'가 저장되면 'MessageB'에는 오프셋 1이 할당된다.
- 순서 보장: 이 로그 구조 덕분에 파티션 내의 메시지는 항상 순차적으로 저장되며, 각 메시지의 순서는 그 오프셋 값으로 보장한다.
- 컨슈머는 오프셋 기준으로 메시지를 순서대로 읽음
- 컨슈머가 3번부터 읽을래! 하면 3번이후의 오프셋만 읽을 수 있음.

## 성능
- 파티션 파일은 OS가 제공하는 페이지캐시를 사용
  - file IO가 메모리에서 처리하기때문에 빠르다. 
- Zero Copy 
  - 디스크 버퍼에서 네트워크 버퍼로 보내는 속도가 빨라진다.
- 브로커가 컨슈머에 대해 하는일이 별로 없다. 
  - 메시지필터, 메시지 재전송과 같은일을 브로커가 하지않고, 프로듀서, 컨슈머가 직접함.
- 묶어서 보내기, 묶어서 받기가 가능하다.
  - 프로듀서 : 일정 크기만큼 메시지를 모아서 전송 가능
  - 컨슈머: 최소 크기만큼 메시지를 모아서 조회 가능
- 낱개 처리보다 처리량 증가 
- 처리량 증대가 쉬움.
  - 1개의 장비의 용량한계가오면 브로커를 추가하고, 파티션을 추가하면됨
  - 컨슈머가 느려? 컨슈머를 추가해 
  - 수평적 확대가 상대적으로 쉽다! 

## 리플리카 - 복제 
- 리플리카: 파티션의 복제본 
  - 복제수만큼 파티션의 복제본이 각 브로커에 생김
- 리더오 팔로워로 구성
- 팔로워는 리더로부터 복제 
- 장애대응
  - 리더가 속한 브로커 장애시 다른 팔로워가 리더가 된다. 


# Producer

- 토픽의 특정 파티션으로 메시지를 전송하며, 실시간 데이터 스트리밍이나 로깅 시스템에 활용된다.
- Producer는 효율적인 데이터 전송과 높은 처리량을 달성하기 위해 다양한 설정을 제공한다. 예를 들어, 메시지 배치 전송, 압축, 재시도 메커니즘 등이 이에 해당한다.  


```java
// 설정 정보
Properties prop = new Properties();
prop.put("bootstrap.servers", "kafaka01:9092,kafka01:9092,kafka01:9092");
prop.put("key.serializer", "org.apache.kafaka.common.serialization.StringSerializer");
prop.pub("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

KafkaProducer<Integer, String> producer = new KafkaProducer<>(prop);

producer.send(new ProducerRecord<>("topicname","key","value")); // ProducerRecord: 브로커에 전송할 메시지 
producer.send(new ProducerRecord<>("topicname","value"));

producer.close();
```

send() -> serializer -> partitioner(파티션 결정) -> 버퍼(배치에 메시지들을 모은다. ) -> sender가 배치를 카프카 브로커로 전송

## sender의 기본동작
- sender는 배치가 찼는지 여부에 상관없이 배치를 꺼내서 브로커에 보낸다. send메서드는 메시지를 계속해서 배치에 누적한다.
- batch.size: 배치크기, 배치가 다차면 바로 전송
- linger.ms: 전송 대기시간
- 전송 성공여부를 알아야하는 경우 
  - send메서드가 반환하는 Future.get() 객체를 사용 -> f.get()은 블로킹됨. 따라서 배치효과가 떨어짐
  - Callback사용 Callback객체를 사용 블로킹하는 방식이 아니라 배치가 쌓이지 않는 단점은 사라짐. 
  - 
## 전송 보장과 ack
프로듀서는 전송을 보장하기위해 ack값을 사용
- ack=0
  - 서버 응답을 기다리지 않음.
  - 전송 보장도 zero 
- ack=1
  - 파티션의 리더에 저장되면 응답받음
  - 리더 장애시 메시지 유실 가능 
- ack = all (또는 -1)
  - 모든 리플리카에 저장되면 응답 받음.
    - 브로커 min.insync.replicas 설정에 따라 달라짐 

## ack + min.insync.replicas 

## 에러 유형
- 전송과정에서 실패
  - 전송 타임 아웃
  - 리더가 문제가 생겨서 새리더를 선출하고 있는중.. 
  - 브로커에서 설정한 메시지 한도 크기를 초과했더거나..

- 전송 전에 실패
  - 직렬화에 실패하거나, 프로듀서 자체 요청 크기 제한을 초과했다거나

### 실패대응1: 재시도 
- 브로커응답에 타임아웃, 리더가 일시적으로 문제가 있으면 재시도 처리. 
- 프로듀서는 기본적으로 재시도를 한다. 브로커에 전송한 과정에서 문제가 생길때, 재시도가 가능한 경우에는 재시도를 한다. 
- send()메서드에서 예외발생시 익셉션 타입에 따라 send() 재호출
- 특별한 이유가 없다면 무한 재시도를 하지 않는다. 

### 실패 대응2: 기록 
- 추후 처리 위해 기록 
  - 별도 파일, DB등을 이용해 실패한 메시지 기록 

### 재시도와 메시지 중복전송 가능성 
- 브로커 응답이 늦게와서 재시도할 경우 중복 발송 가능

### 재시도와 순서 
- 블록킹없이 한 커넥션에서 전송할수 있는 최대 전송중인 요청 개수
- 배치1전송 -> 실패, 배치2 전송->성공, 배치3 전송 -> 성공, 배치 1전송 재시도 -> 성공 
- 재시도는 메시지 저장순서를 바꾸기도한다. 저장순서가 정말로 중요한 경우에는 max.in.flight.requestts.per.connection을 1로 지정

# 컨슈머
```java
Properties prop = new Properties();
prop.put("bootstrap.servers", "localhost9092");
prop.put("group.id", "group1"); 
prop.put("key.serializer", "org.apache.kafaka.common.serialization.StringDeserializer"); 
prop.pub("value.serializer", "org.apache.kafka.common.serialization.StringDeserializer");

KafkaConsumer<String,String> consumer = new KafkaConsumer<String,String>(prop);
consumer.subscribe(Collections.singleton("simple"));// 토픽구독
  
while(조건) {
	ConsumerRecords<String,String> records = consumer.poll(Duration.ofMillis(100));// poll은 일정시간대기하다가 브로커로부터 컨슈머레코드 목록을 읽어온다.
	for(ConsumerRecord<String,String> record:records) {
		System.out.println(record.value() + ":" + record.topic() + ":" + record.partition() + ":" + record.offset());
  }
}

consumer.close();
```

## 토픽 파티션은 그룹단위로 할당 
- 컨슈머 그룹 단위로 파티션 할당
- 파티션 개수보다 컨슈머그룹이 많으면 컨슈머는 논다. 
  * 컨슈머개수가 파티션 개수보다 많으면 안된다.
- 파티션이 두개이고 컨슈머가 한개라면 컨슈머 한개가 두 파티션으로부터 데이터를 읽어온다. 
- 컨슈머를 하나 추가하면 각 컨슈머가 파티션에 연결된다. 
 

## 커밋과 오프셋 

### 커밋된 오프셋이 없는 경우
- 처음 접근이거나 커밋한 오프셋이 없는경우
- auto.offset.reset 설정사용
- earliest: 맨처음 오프셋 사용
- latest: 가장 마지막 오프셋 사용 (기본값)
- none: 컨슈머 그룹에 대한 이전 커밋이 없으면 익셉션 발생
- 보통 earliest,latest 사용

### 컨슈머 설정
- fetch.min.bytes: 조회시 브로커가 전송할 최소 데이터 크기 
  - 이값이 크면 대기시간은 늘지만 처리량이 증가
- fetch.max.wait.ms: 데이터가 최소 크기가 될때까지 기다릴 시간
- max.partition.fetch.bytes: 파티션당 서버가 리턴할 수 있는 최대 크기


### 자동 커밋/ 수동 커밋 
enable.auto.commit 설정
- true(기본값): 일정 주기로 컨슈머가 읽은 오프셋을 커밋
- false: 수동으로 커밋 실행

### 수동커밋 : 동기/비동기 커밋

### 재처리와 순서
카프카를 사용할떄 주의할점은 컨슈머가 동일한 메시지를 읽어올수 있다는 것이다. 
일시적으로 커밋에 실패했을때
- 컨슈머는 멱등성(idempotence)을 고려해야함. 
데이터 특성에 따라 타임스탬프, 일련번호 등을 사용 

- 세션 타임아웃, 하트비트, 최대 poll 간격 
- 브로커는 일정시간 컨슈머로부터 하트비트가 없으면 컨슈머를 그룹에서 뺴고 리밸런스 진행


### 주의: 쓰레드 안전하지 않음. 
KafkaConsumer는 쓰레드에 안전하지 않다.
- 여러 쓰레드에서 카프카 컨슈머 객체를 동시에 쓰면 안된다. 
- wakeup() 메서드는 예외 
- wakeup() 메서드를 제외한 나머지 메서드는 여러스레드에서 사용하면 안된다